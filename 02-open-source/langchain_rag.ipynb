{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "306b736c-38a6-4dbc-a078-887183b5db18",
   "metadata": {},
   "source": [
    "# Creating a LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27076f7-84ed-4ebf-a420-f7aece1fb5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"tinyllama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c16a5dd-ff21-4fc9-96b1-052b18b37cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangSmt.io offers several tools and services to aid in test development and execution, including:\\n\\n1. Test automation - LangSmt.io provides automated test scripts in various languages (Java, Python, C#, etc.) and test frameworks such as Robotium, Appium, Selenium, and NUnit. This can be useful for reducing the time and effort required to write automated tests.\\n\\n2. Test suite creation - LangSmt.io offers tools that allow you to create test suites and execute them in a simulated environment. You can run and debug the tests, view results, and adjust settings as needed.\\n\\n3. Automatic testing - LangSmt.io also provides automatic testing capabilities through its AI-powered features such as regression testing, dynamic testing (e.g., smoke tests), or functional testing. These features help to reduce the time required for manual testing while ensuring that your code meets the expected functionality and performance requirements.\\n\\n4. Test data generation - LangSmt.io can generate test data based on input parameters such as user inputs, randomized data, or generated values. This can help you to simulate different scenarios and ensure that your application functions correctly for each scenario.\\n\\nOverall, LangSmt.io provides a holistic solution to aid in testing your AI-powered application. Whether you're a tester or development team, LangSmt.io has tools and services that can help automate your testing processes.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e94463df-4764-4a8d-a661-d95b5fe0a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant! Your name is Bob\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd937bf2-2c3d-4eeb-95b5-08199c381fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8997509-1a37-4815-ab02-961e2af72759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: My name is Bob. Human: what is your last name?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is your name?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a977c97-1f27-4bfa-81ab-45691bfa704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aceb035-661b-4050-baad-a38dcb986cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf8b8dc0-1af5-46a7-9c3c-f3cac103b7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LangSmith offers a range of testing services to help you optimize your software development process and achieve better results for your product or service. Our team of experts has experience in performing various types of testing, including functional, performance, usability, and regression testing. We can help with developing test plans, executing tests, and analyzing the results to ensure that your software meets your quality standards and delivers the expected outcomes. Whether you need a single test run or an extensive testing campaign, LangSmith's experts will work closely with you to identify and resolve any issues that may arise during development or deployment.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7074e9b8-286e-4f31-ad7e-99b0fdd9d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59913fa7-f56d-4e37-92d0-677c8339eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdbd6c60-770e-44b4-b4f1-9a33bd5baf7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith, the artificial intelligence writing service, can provide technical documentation writers to assist you in conducting thorough tests of your software or product. By using our AI-powered technology and expert writers, we can ensure that the documentations are easy to understand, accurate, and comprehensive. We can also conduct test automation and provide valuable feedback for bug fixes and improvements. In summary, our team can help you with testing, which is an essential aspect of software development.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9f137-2336-4a6d-bcc8-d91a41f67400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af62a422-c4b5-465e-8d30-465fda4c9255",
   "metadata": {},
   "source": [
    "# Creating a Retrieval Chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088c9b95-019a-4f96-b3fd-0057c8fac9f9",
   "metadata": {},
   "source": [
    "To properly answer the original question (\"how can langsmith help with testing?\"), we need to provide additional context to the LLM. We can do this via retrieval. Retrieval is useful when you have too much data to pass to the LLM directly. You can then use a retriever to fetch only the most relevant pieces and pass those in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52372c8e-e70c-4665-ad57-ec690f6b7a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\willi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\willi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8a1ecbe-185b-4bee-8f64-7376182b3aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bffdc664-6cc2-4c3c-847f-1bd557332714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(model='tinyllama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7d52412-80b0-46ff-97cb-1d328ac263af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector_db = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0095d825-e498-444c-ac80-f850d1672824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5fba1-8e52-46db-a4ca-6c0269c3ec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results, LangSmith is a platform for LLM application development, monitoring, and testing. In this guide, we’ll highlight the breadth of workflows LangSmith supports and how they fit into each stage of the application development lifecycle. We hope this will inform users how to best utilize this powerful platform or give them something to consider if they’re just starting their journey.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558a1033-85ca-4e78-b8e3-c7a60e854a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector_db.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d38fe9-48f2-497b-9350-dae1e7f44c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef9dae0-534b-475d-92a2-9f833b89107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b94c83-1cf5-4daf-be97-f722bc14755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "abb1c1d3-794f-4b4d-99a2-b2e6d257bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f814e678-fb09-41d7-b45d-335d6464aa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6e30b8-50a9-47b5-8b88-6380549fa962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
